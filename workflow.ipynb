{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import os\n",
    "from dataset import StrokeDataset, collate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "home = os.environ['HOME']\n",
    "data_dir = \"./data\"\n",
    "edge_dir = \"./edge/time_space_lateral\"\n",
    "trainset = StrokeDataset(data_dir, edge_dir, \"train\", num_classes)\n",
    "validset = StrokeDataset(data_dir, edge_dir, \"valid\", num_classes)\n",
    "testset = StrokeDataset(data_dir, edge_dir, \"test\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = th.device('cuda')\n",
    "\n",
    "train_loader = DataLoader(trainset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=collate(device))\n",
    "\n",
    "valid_loader = DataLoader(validset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=False,\n",
    "                          collate_fn=collate(device))\n",
    "\n",
    "test_loader = DataLoader(testset,\n",
    "                         batch_size=32,\n",
    "                         shuffle=False,\n",
    "                         collate_fn=collate(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def print_result(count):\n",
    "    num_classes = count.shape[0]\n",
    "    if num_classes == 5:\n",
    "        id_to_tag = ['Graph', 'Text', 'Table', 'List', 'Math']\n",
    "    elif num_classes == 2:\n",
    "        id_to_tag = ['Non-text', 'Text']\n",
    "    \n",
    "    # Confusion matrix with accuracy for each tag\n",
    "    print ((\"{: >2}{: >9}{: >9}%s{: >9}\" % (\"{: >9}\" * num_classes)).format(\n",
    "        \"ID\", \"NE\", \"Total\",\n",
    "        *([id_to_tag[i] for i in range(num_classes)] + [\"Percent\"]))\n",
    "    )\n",
    "    for i in range(num_classes):\n",
    "        print ((\"{: >2}{: >9}{: >9}%s{: >9}\" % (\"{: >9}\" * num_classes)).format(\n",
    "            str(i), id_to_tag[i], str(count[i].sum()),\n",
    "            *([count[i][j] for j in range(num_classes)] +\n",
    "              [\"%.3f\" % (count[i][i] * 100. / max(1, count[i].sum()))])\n",
    "        ))\n",
    "\n",
    "    # Global accuracy\n",
    "    accuracy = 100. * count.trace() / max(1, count.sum())\n",
    "    print (\"Stroke accuracy: %i/%i (%.5f%%)\" % (\n",
    "        count.trace(), count.sum(), accuracy)\n",
    "    )\n",
    "    \n",
    "def evaluate(model, loader, num_classes, name):\n",
    "    model.eval()\n",
    "    print(name + \":\")\n",
    "    count = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "    for it, (fg, lg) in enumerate(loader):\n",
    "        logits = model(fg)\n",
    "        _, predictions = th.max(logits, dim=1)\n",
    "        labels = lg.ndata['y']\n",
    "        predictions = predictions.cpu().numpy()\n",
    "        labels = labels.cpu().numpy()\n",
    "        count += confusion_matrix(labels, predictions)\n",
    "    model.train()\n",
    "    \n",
    "    print_result(count)\n",
    "    \n",
    "    accuracy = 100. * count.trace() / max(1, count.sum())\n",
    "    return accuracy, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyu/anaconda2/envs/py36/lib/python3.6/site-packages/dgl/frame.py:204: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n",
      "  dgl_warning('Initializer is not set. Use zero initializer instead.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0, loss 0.330400\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    20824     5723   78.442\n",
      " 1     Text   116801     3010   113791   97.423\n",
      "Stroke accuracy: 134615/143348 (93.90783%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     8048     2856   73.808\n",
      " 1     Text    57821     1552    56269   97.316\n",
      "Stroke accuracy: 64317/68725 (93.58603%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    10403     2565   80.221\n",
      " 1     Text    57959     1843    56116   96.820\n",
      "Stroke accuracy: 66519/70927 (93.78516%)\n",
      "Epoch   1, loss 0.168309\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    22141     4406   83.403\n",
      " 1     Text   116801     2815   113986   97.590\n",
      "Stroke accuracy: 136127/143348 (94.96261%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     8605     2299   78.916\n",
      " 1     Text    57821     1439    56382   97.511\n",
      "Stroke accuracy: 64987/68725 (94.56093%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11090     1878   85.518\n",
      " 1     Text    57959     1585    56374   97.265\n",
      "Stroke accuracy: 67464/70927 (95.11752%)\n",
      "Epoch   2, loss 0.138793\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    22378     4169   84.296\n",
      " 1     Text   116801     2078   114723   98.221\n",
      "Stroke accuracy: 137101/143348 (95.64207%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     8802     2102   80.723\n",
      " 1     Text    57821     1110    56711   98.080\n",
      "Stroke accuracy: 65513/68725 (95.32630%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11153     1815   86.004\n",
      " 1     Text    57959     1189    56770   97.949\n",
      "Stroke accuracy: 67923/70927 (95.76466%)\n",
      "Epoch   3, loss 0.124538\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    23015     3532   86.695\n",
      " 1     Text   116801     2190   114611   98.125\n",
      "Stroke accuracy: 137626/143348 (96.00832%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9154     1750   83.951\n",
      " 1     Text    57821     1259    56562   97.823\n",
      "Stroke accuracy: 65716/68725 (95.62168%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11506     1462   88.726\n",
      " 1     Text    57959     1316    56643   97.729\n",
      "Stroke accuracy: 68149/70927 (96.08330%)\n",
      "Epoch   4, loss 0.115628\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    23076     3471   86.925\n",
      " 1     Text   116801     2046   114755   98.248\n",
      "Stroke accuracy: 137831/143348 (96.15132%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9170     1734   84.098\n",
      " 1     Text    57821     1180    56641   97.959\n",
      "Stroke accuracy: 65811/68725 (95.75991%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11525     1443   88.873\n",
      " 1     Text    57959     1175    56784   97.973\n",
      "Stroke accuracy: 68309/70927 (96.30888%)\n",
      "Epoch   5, loss 0.109515\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    23343     3204   87.931\n",
      " 1     Text   116801     1753   115048   98.499\n",
      "Stroke accuracy: 138391/143348 (96.54198%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9364     1540   85.877\n",
      " 1     Text    57821     1030    56791   98.219\n",
      "Stroke accuracy: 66155/68725 (96.26046%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11584     1384   89.328\n",
      " 1     Text    57959     1059    56900   98.173\n",
      "Stroke accuracy: 68484/70927 (96.55561%)\n",
      "Epoch   6, loss 0.102902\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    23866     2681   89.901\n",
      " 1     Text   116801     2039   114762   98.254\n",
      "Stroke accuracy: 138628/143348 (96.70731%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9565     1339   87.720\n",
      " 1     Text    57821     1275    56546   97.795\n",
      "Stroke accuracy: 66111/68725 (96.19644%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11810     1158   91.070\n",
      " 1     Text    57959     1244    56715   97.854\n",
      "Stroke accuracy: 68525/70927 (96.61342%)\n",
      "Epoch   7, loss 0.096178\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    24206     2341   91.182\n",
      " 1     Text   116801     2111   114690   98.193\n",
      "Stroke accuracy: 138896/143348 (96.89427%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9754     1150   89.453\n",
      " 1     Text    57821     1285    56536   97.778\n",
      "Stroke accuracy: 66290/68725 (96.45689%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11926     1042   91.965\n",
      " 1     Text    57959     1356    56603   97.660\n",
      "Stroke accuracy: 68529/70927 (96.61906%)\n",
      "Epoch   8, loss 0.096356\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    24262     2285   91.393\n",
      " 1     Text   116801     2131   114670   98.176\n",
      "Stroke accuracy: 138932/143348 (96.91938%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9753     1151   89.444\n",
      " 1     Text    57821     1215    56606   97.899\n",
      "Stroke accuracy: 66359/68725 (96.55729%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11894     1074   91.718\n",
      " 1     Text    57959     1311    56648   97.738\n",
      "Stroke accuracy: 68542/70927 (96.63739%)\n",
      "Epoch   9, loss 0.091951\n",
      "train:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    26547    23965     2582   90.274\n",
      " 1     Text   116801     1615   115186   98.617\n",
      "Stroke accuracy: 139151/143348 (97.07216%)\n",
      "valid:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    10904     9573     1331   87.793\n",
      " 1     Text    57821      945    56876   98.366\n",
      "Stroke accuracy: 66449/68725 (96.68825%)\n",
      "test:\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11749     1219   90.600\n",
      " 1     Text    57959     1048    56911   98.192\n",
      "Stroke accuracy: 68660/70927 (96.80376%)\n",
      "Best round: 9\n",
      "ID       NE    Total Non-text     Text  Percent\n",
      " 0 Non-text    12968    11749     1219   90.600\n",
      " 1     Text    57959     1048    56911   98.192\n",
      "Stroke accuracy: 68660/70927 (96.80376%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gcn import GCNNet\n",
    "from gat import GAT\n",
    "\n",
    "in_feats = 23\n",
    "edge_f_dim = 19\n",
    "hidden_feats = 8\n",
    "num_heads = 8\n",
    "num_out_heads = 8\n",
    "num_layers = 3\n",
    "residual = True\n",
    "in_drop = 0\n",
    "attn_drop = 0.2\n",
    "lr = 5e-3\n",
    "weight_decay = 5e-4\n",
    "alpha = 0.2\n",
    "\n",
    "num_epoches = 10\n",
    "heads = ([num_heads] * num_layers) + [num_out_heads]\n",
    "\n",
    "# model = GCNNet(in_feats, hidden_feats, num_classes).to(device)\n",
    "model = GAT(num_layers, in_feats, edge_f_dim, hidden_feats, num_classes,\n",
    "            heads, F.elu, in_drop, attn_drop, alpha, residual).to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "epoch_losses = []\n",
    "best_valid_acc = 0\n",
    "best_test_acc = 0\n",
    "best_round = 0\n",
    "\n",
    "for epoch in range(num_epoches):\n",
    "    epoch_loss = 0\n",
    "    for it, (fg, lg) in enumerate(train_loader):\n",
    "        logits = model(fg)\n",
    "        labels = lg.ndata['y']\n",
    "        loss = loss_func(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.detach().item()\n",
    "        \n",
    "    epoch_loss /= (it + 1)\n",
    "    print('Epoch {:3d}, loss {:4f}'.format(epoch, epoch_loss))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    \n",
    "    train_acc, _= evaluate(model, train_loader, num_classes, \"train\")\n",
    "    valid_acc, _ = evaluate(model, valid_loader, num_classes, \"valid\")\n",
    "    if valid_acc > best_valid_acc:\n",
    "        test_acc, test_conf_mat = evaluate(model, test_loader, num_classes, \"test\")\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_conf_mat = test_conf_mat\n",
    "            best_round = epoch\n",
    "\n",
    "print(\"Best round: %d\" % best_round)\n",
    "print_result(best_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
